<!DOCTYPE html>
<html>
  <head>
    <title>Lectures by Tiansi Dong</title>
    <link rel="stylesheet" href="styles/base.css?v=<?=time();?>">
	<meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="js/slideshow.js"></script>
    <script src="js/jquery-3.5.1.js"></script>
  </head>
  <style>
div.journal-select {
  width: 200px;
  word-wrap: break-word;
}
</style>
  <body>
	<div class="nav-container" id="navContainer">

    <nav class="nav">
      <a href="./">
        <img class="nav__logo" src="img/ucsd.svg" alt="Uni Bonn">
      </a>
      <span class="nav__menu" onClick="expandMenu()">&#9776;</span>
      <script>
        function expandMenu() {
          document.getElementById('navContainer').classList.toggle('expanded');
        }
      </script>
      <div class="nav__separator"></div>
      <a href="./" class="nav__item">Home</a> 
      <a href="teaching.html" class="nav__item">Lectures</a>
      <a href="https://neurmad.github.io/" class="nav__item">NeurMAD@AAAI</a>
      <a href="https://chum2025.github.io/" class="nav__item">CHum@COLING</a>
      <a href="https://neusymbridge.github.io/" class="nav__item">NeusymBridge@COLING</a>
      <a href="dagstuhl2021.html" class="nav__item">Dagstuhl'21</a>
      <a href="beijing2019.html" class="nav__item">Beijing'19</a>
      <a href="publications.html" class="nav__item">Publications</a>
      <!-- sub menu ------------------

              <a href="team.php" class="nav__item">People</a>
              <div class="nav-sub">
                  <a href="team.php" class="nav__item">People <small><small><small><small>&#9660</small></small></small></small></a>
                  <div class="nav-sub__item">
                      <a href="team.php">Lab members</a>
                      <a href="gallery.html">Gallery</a>
                  </div>
              </div>
      -------------------------------- -->
      <!--a href="openings.html" class="nav__item">Openings</a>
      <a href="intranet.html" class="nav__item">Resources</a>
      <a href="tour.html" class="nav__item">Lab Tour</a-->
      <a href="./" class="nav__item">Contact</a>
    </nav>
  </div>


    <section>
      <div class="journal-select">
        <span class="journal-select__text">Semester </span></br>
        <a href="#20245"><span data-block-id="20245" class="journal-select__item">2024/25</span></a>
        <a href="#20234"><span data-block-id="20234" class="journal-select__item">2023/24</span></a>
        <a href="#2023"><span data-block-id="2023" class="journal-select__item">2023</span></a>
        <a href="#2022"><span data-block-id="2022" class="journal-select__item">2022</span></a>
        <a href="#2021"><span data-block-id="2021" class="journal-select__item">2021/22</span></a>
        <a href="#2020"><span data-block-id="2020" class="journal-select__item">2021</span></a>
        <a href="#2019"><span data-block-id="2019" class="journal-select__item">2020</span></a>
        <a href="#2018"><span data-block-id="2018" class="journal-select__item">2019</span></a>
        <a href="#ealier"><span data-block-id="earlier" class="journal-select__item">Earlier</span></a>
      </div>
	</section>
    <section class="journal light">


      <ul id="20245" class="publications-container">
        <h2 class="section__title">2024/2025 Winter Semester</h2>
          <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4326 - Explainable AI and Applications</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b>, <b>Rafet Sifa</b></span>
            
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">
                Endowing machines with knowledge has long been regarded as one of the important goals of AI. To fulfil this aim, researchers have built many knowledge bases at different scales for different knowledge types. Traditionally, symbols and their relations represent knowledge for reasoning. By contrast, large language models (LLMs) follow quite a different paradigm: the tradition of connectionism and neural networks. It employs distributional numerical vectors/matrices to represent the knowledge. This way, almost all knowledge types can be represented and embodied into a unified semantic space. However, compared with traditional symbolic knowledge bases, LLMs still have limitations, including inexplainability, approximation, and hallucination. This lecture will start with simple logic deduction and show that the traditional neural approach can not do explainable and rigorous reasoning. Then, step-by-step, we motivate geometric solutions, by opening the black box of deep learning and revisiting classic research in cognitive psychology. We give detailed instructions on how to develop neuro-symbolic geometric embedding to logical deduction that inherits both good features from neural computing and classic symbolic AI. After that, we apply our geometric neural computing for a variety of fundamental cognitive reasoning tasks.  
              </p>
              <!--img class="publication-item__image" src="img/publications/journals/141.png" alt="Figure" /-->
            </details>
            
            <span class="publication-item__title normal">Lecture Monday 10:15 -- 11:45 Oct. 21, 2024 -- Jan. 27, 2025,  B-IT 0.109</span>
            <span class="publication-item__title normal">Exercise Monday 10:15 -- 11:45 Oct. 23, 2024 -- Jan. 29, 2025, B-IT 0.109</span>
            <span class="publication-item__title normal">1st Exam (90 Minutes): 9:00 -- 11:00, Feb 7, 2025</span>
            <span class="publication-item__title normal">2nd Exam (90 Minutes): 9:00 -- 11:00, Mar 12, 2025</span>
               

            <ol class="customIndent">
              <div class="publications-section-container">
                <div class="publication-item">
                  <span class="publication-item__subtitle">Oct. 21 <b class="teaching-item"> Introduction </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle"> Oct. 28 <b class="teaching-item"> Syllogistic Rasoning -- The Micro-world for High-Level Cognition (I)</b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle"> Nov. 4 <b class="teaching-item"> Syllogistic Rasoning -- The Micro-world for High-Level Cognition (II) </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Nov. 11 <b class="teaching-item"> Supervised Deep-Learning for Syllogistic Rasoning</b> </span>
                </div>
                <div class="publication-item"> 
                  <span class="publication-item__subtitle">Nov. 18 <b class="teaching-item"> Open Blackbox of Deep-Learning Neural Networks </b> </span>
                </div>
                <div class="publication-item"> 
                  <span class="publication-item__subtitle">Nov. 25 <b class="teaching-item"> Can supervised Deep-Learning reason? (I) </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 2 <b class="teaching-item"> Can supervised Deep-Learning reason? (II)</b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 9 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (I) - the task </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 16 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (II) - the representation </b> </span>
                </div>
                <div class="publication-item"> 
                  <span class="publication-item__subtitle">Dec. 23 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (III) - the motor </b> </span>
                </div>
                <div class="publication-item"> 
                  <span class="publication-item__subtitle">Dec. 30 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (IV) - the process </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 6 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (V) - the proof (part 1) </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 13 <b class="teaching-item"> Sphere Neural-Network for Syllogistic Reasoning (V) - the proof (part 2) </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 20 <b class="teaching-item"> Geometric approach to neural-symbolic unification  </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 27 <b class="teaching-item"> Sphere Embedding: The Atom for Explainable AI </b> </span>
                </div>
              </div>
            </ol>
            </div>
          </div>
        </div>
    </ul>

      <ul id="2023/2024" class="publications-container">
        <h2 class="section__title">2023/2024 Winter Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal">Seminar on Multimodal Transformers and Applications</b></span>
            <span class="publication-item__authors"> <b>Rafet Sifa, Tiansi Dong, Kostadin Cvejoski, Lorenz Sparrenberg</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">
                Neural networks can take almost any kind of senory inputs, e.g., visual, audio, video, text, tactic, and embed them into the vector space. 
                This creates the possibility to develop a unified meaning representation for cross-modal reasoning. 
                In this seminar, we survey multimodal neural computing, with a focus on the relations among language, images, knowledge, and emotion. </p>
            </details>
            <span class="publication-item__title normal">Kickoff 14:00 -- 1500 Nov. 15, 2023, Loc.: B-IT 2.113</span>
           
          </div>
        </div>

          <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4326 - Explainable AI and Applications</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b>, <b>Rafet Sifa</b></span>
            
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">
                Endowing machines with knowledge has long been regarded as one of the important goals of AI. To fulfil this aim, researchers have built many knowledge bases at different scales for different knowledge types. Traditionally, symbols and their relations represent knowledge for reasoning. By contrast, large language models (LLMs) follow quite a different paradigm: the tradition of connectionism and neural networks. It employs distributional numerical vectors/matrices to represent the knowledge. This way, almost all knowledge types can be represented and embodied into a unified semantic space. However, compared with traditional symbolic knowledge bases, LLMs still have limitations, including inexplainability, approximation, and hallucination. This lecture will start with simple logic deduction and show that the traditional neural approach can not do explainable and rigorous reasoning. Then, step-by-step, we motivate geometric solutions, by opening the black box of deep learning and revisiting classic research in cognitive psychology. We give detailed instructions on how to develop neuro-symbolic geometric embedding to logical deduction that inherits both good features from neural computing and classic symbolic AI. After that, we apply our geometric neural computing for a variety of fundamental cognitive reasoning tasks.  
              </p>
              <!--img class="publication-item__image" src="img/publications/journals/141.png" alt="Figure" /-->
            </details>
            
            <span class="publication-item__title normal">Lecture Monday 10:15 -- 11:45 Nov. 6, 2023 -- Jan. 29, 2024, Loc.: B-IT 2.113</span>
            <span class="publication-item__title normal">Exercise Monday 10:15 -- 11:45 Nov. 8, 2023 -- Jan. 31, 2024, Loc.: B-IT 2.113</span>
            <span class="publication-item__title normal">1st Exam (90 Minutes): Feb 26, 10:15 to 12:15, location: 0.109</span>
            <span class="publication-item__title normal">2nd Exam (90 Minutes): March 25, 10:15 to 12:15, location: 0.107</span>
               

            <ol class="customIndent">
              <div class="publications-section-container">
                <div class="publication-item">
                  <span class="publication-item__subtitle">Nov. 06 <b class="teaching-item"> Introduction </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle"> Nov. 13 <b class="teaching-item"> Blackbox Supervised Deep-Learning for Syllogistic Rasoning (EN) </b> </span>
                </div>
                <div class="publication-item">
                  <span class="publication-item__subtitle"> Nov. 20 <b class="teaching-item"> XAI to Open Blackbox Deep-Learning Neural Networks (ENN)</b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Nov. 27 <b class="teaching-item"> Self-Explainable Deep-Learning for Syllogistic Rasoning (1)</b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 4 <b class="teaching-item"> Self-Explainable Deep-Learning for Syllogistic Rasoning (2)</b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 11 <b class="teaching-item"> EN and ENN as Simulations of System 1 and System 2 of the mind</b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Dec. 18 <b class="teaching-item"> Geometric approach to neural-symbolic unification</b> </span>
                </div>
 

                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 8 <b class="teaching-item"> Neural Reasoning with Part-Whole Relations </b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 15 <b class="teaching-item"> Spatial Reasoning (I): Way-finding, from Tolman's Rats to Spatial Hoare Logic </b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 22 <b class="teaching-item"> Spatial Reasoning (II): Recognising Home (Dynamic Environments) and Humor </b> </span>
                </div>

                <div class="publication-item">
                  <span class="publication-item__subtitle">Jan. 29 <b class="teaching-item"> Sphere Embedding: The Atom for Explainable AI </b> </span>
                </div>

              </div>
            </ol>
            </div>
          </div>
        </div>
    </ul>

      <ul id="2023" class="publications-container">
        <h2 class="section__title">2023 Summer Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> Fraunhofer Lab Representation Learning</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong and Rafet Sifa</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">.</p>
            </details>
          </div>
        </div>
        </div>
      </ul>

      <ul id="2022" class="publications-container">
        <h2 class="section__title">2022 Summer Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4306 - Lab Development and Application of Data Mining and Learning Systems: AI Language and Vision</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">.</p>
            </details>
          </div>
        </div>
        </div>
      </ul>

      <ul id="2021/2022" class="publications-container">
          <h2 class="section__title">2021/2022 Winter Semester</h2>
            <div class="publications-section-container">
            <div class="publication-item">
              <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4326 - Explainable AI and Applications</b></span>
              <span class="publication-item__authors"> <b>Tiansi Dong</b>, Siba Mohsen</span>
              <span class="publication-item__title normal">1st Exam (90 Minutes): Feb 25, 11:00 to 14:00, location: Friedrich-Hirzebruch Allee 5 - Hörsaal 2</span>
              <span class="publication-item__title normal">2nd Exam (90 Minutes): April 1, 11:00 to 14:00, location: Friedrich-Hirzebruch Allee 5 - Hörsaal 2</span>
              <span class="publication-item__title normal">Lecture Monday 12:30 -- 14:00 from Oct. 18, 2021 to Jan. 31, 2022</span>
              <span class="publication-item__title normal">Exercise Monday 14:30 -- 16:00 from Oct. 25, 2021 to Jan. 31, 2022</span>
              <details>
                <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
                <p class="publication-item__text">Most of the deep-learning systems are black-box systems and lack of explainability and trustworthiness.
                  In this lecture, I will start by introducing the achievements and limitations of large Deep-Learning systems, e.g. Watson, GPT,
                  self-driving cars. Then I introduce two different neural approaches to syllogistic reasoning – one from the black box perspective,
                  the other from the white box perspective. The state-of-the-art XAI approaches will be applied for the understanding of the black-box
                  neural system. The white-box system will be followed by an introduction of spatial representation and reasoning, then continue to
                  introduce features into spheres, and land on neural understanding of Humors. Background theories in cogitive science and humor
                  research will be introduced, e.g., the dual-model theories of mind(System 1 and 2), laws of cognition, the Theory of Verbal Humor.</p>
                <!--img class="publication-item__image" src="img/publications/journals/141.png" alt="Figure" /-->
              </details>
              <ol class="customIndent">
                <div class="publications-section-container">
                  <div class="publication-item">
                    <span class="publication-item__subtitle">Oct. 18 <b class="teaching-item"> Introduction </b> </span>
                  </div>
                  <div class="publication-item">
                    <span class="publication-item__subtitle">Oct. 25 <b class="teaching-item"> Blackbox Supervised Deep-Learning for Syllogistic Rasoning (EN) </b> </span>
                  </div>
                  <div class="publication-item">
                    <span class="publication-item__subtitle">Nov. 08 <b class="teaching-item"> XAI to Open Blackbox Deep-Learning Neural Networks (ENN)</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Nov. 15 <b class="teaching-item"> Self-Explainable Deep-Learning for Syllogistic Rasoning (1)</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Nov. 22 <b class="teaching-item"> Self-Explainable Deep-Learning for Syllogistic Rasoning (2)</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Nov. 29 <b class="teaching-item"> Self-Explainable Deep-Learning for Syllogistic Rasoning (3)</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Dec. 6 <b class="teaching-item"> EN and ENN as Simulations of System 1 and System 2 of the mind</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Dec. 13 <b class="teaching-item"> Geometric approach to neural-symbolic unification</b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Dec. 20 <b class="teaching-item"> Mid term examination </b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Jan. 10 <b class="teaching-item"> Neural Reasoning with Part-Whole Relations </b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Jan. 17 <b class="teaching-item"> Spatial Reasoning (I): Way-finding, from Tolman's Rats to Spatial Hoare Logic </b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Jan. 24 <b class="teaching-item"> Spatial Reasoning (II): Recognising Home (Dynamic Environments) and Humor </b> </span>
                  </div>

                  <div class="publication-item">
                    <span class="publication-item__subtitle">Jan. 31 <b class="teaching-item"> Sphere Embedding: The Atom for Explainable AI </b> </span>
                  </div>

                </div>
              </ol>
              </div>
            </div>
          </div>
      </ul>

      <ul id="2021" class="publications-container">
        <h2 class="section__title">2021 Summer Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4306 - Lab Development and Application of Data Mining and Learning Systems: AI Language and Vision</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">.</p>
            </details>
          </div>
        </div>
        </div>
      </ul>

      <ul id="2020/2021" class="publications-container">
        <h2 class="section__title">2020/2021 Winter Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4306 - Lab Development and Application of Data Mining and Learning Systems: AI Language and Vision</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">.</p>
            </details>
          </div>
        </div>
        </div>
      </ul>

      <ul id="2020" class="publications-container">
        <h2 class="section__title">2021 Summer Semester</h2>
        <div class="publications-section-container">
          <div class="publication-item">
            <span class="publication-item__subtitle"><b class="publication-item__journal"> MA-INF 4306 - Lab Development and Application of Data Mining and Learning Systems: AI Language and Vision</b></span>
            <span class="publication-item__authors"> <b>Tiansi Dong</b></span>
            <span class="publication-item__title normal"></span>
            <span class="publication-item__title normal"></span>
            <details>
              <summary class="publication-item__abstract"><b>Short introduction</b> (click)</summary>
              <p class="publication-item__text">.</p>
            </details>
          </div>
        </div>
        </div>
      </ul>



    </section>
    <section class="contact" id="footer"> </section>
    <script>
		$("#footer").load("include/footer.html");
	</script>
  </body>
  <script>
    function expandMenu() {
      document.getElementById('navContainer').classList.toggle('expanded');
    }
  </script>
</html>
